{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf447d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate tf_gpu\n",
    "\n",
    "#importando pacotes\n",
    "import input_data\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#Limitando o uso da GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4371b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ativando compatibilidade com tensorflow1\n",
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "969940ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33268d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros\n",
    "learning_rate = 0.001\n",
    "training_iters = 250000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Parâmetros da rede\n",
    "n_input = 784 # MNIST data input (shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Dropout\n",
    "# Aplicamos o dropout para reduzir o overfitting. O dropout vai eliminar algumas unidades (nas camadas ocultas, de entrada e de saída) na rede neural.\n",
    "# A decisão sobre qual neurônio será eliminado é randômica e aplicamos uma probabilidade para isso. Esse parâmetro pode ser ajustado para otimizar o desempenho da rede.\n",
    "dropout = 0.75 # Dropout, probabilidade para manter unidades\n",
    "\n",
    "# Graph input\n",
    "x = tf.compat.v1.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.compat.v1.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.compat.v1.placeholder(tf.float32) # dropout \n",
    "\n",
    "# Convertendo o input (x) para um tensor\n",
    "_X = tf.reshape(x, shape = [-1, 28, 28, 1])\n",
    "\n",
    "# Funções para criar o modelo\n",
    "# A função tf.nn.conv2d() computa convoluções 2D a partir do tensor de input. A esse resultado adicionamos o bias.\n",
    "# A função tf.nn.relu() é usada como função de ativação nas camadas ocultas. Aplicamos a ReLu aos valores de retorno das camadas de convolução.\n",
    "# O parâmetro padding indica que o tensor de output terá o mesmo tamanho do tensor de entrada.\n",
    "def conv2d(img, w, b):\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(input=img, filters=w, strides = [1, 1, 1, 1], padding = 'VALID'), b))\n",
    "\n",
    "# Após a operação de convolução, realizamos o passo de pooling que simplifica a informação de output previamente criada pela camada de convolução.\n",
    "def max_pool(img, k):\n",
    "    return tf.nn.max_pool2d(input=img, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = 'VALID')\n",
    "\n",
    "# Pesos\n",
    "# Cada neurônio da camada oculta é conectado a um pequeno grupo de tensores de entrada (input) de dimensão 5x5. Com isso, a camada oculta terá um tamanho de 24x24.\n",
    "wc1 = tf.Variable(tf.random.normal([5, 5, 1, 32])) # 5x5 conv, 1 input, 32 outputs\n",
    "wc2 = tf.Variable(tf.random.normal([5, 5, 32, 64])) # 5x5 conv, 32 inputs, 64 outputs\n",
    "wd1 = tf.Variable(tf.random.normal([4*4*64, 1024])) # completamente conectada, 4*4*64 inputs, 1024 outputs\n",
    "wout = tf.Variable(tf.random.normal([1024, n_classes])) # 1024 inputs, 10 outputs (class prediction)\n",
    "\n",
    "# Bias\n",
    "bc1 = tf.Variable(tf.random.normal([32]))\n",
    "bc2 = tf.Variable(tf.random.normal([64]))\n",
    "bd1 = tf.Variable(tf.random.normal([1024]))\n",
    "bout = tf.Variable(tf.random.normal([n_classes]))\n",
    "\n",
    "# Camada 1 de convolução\n",
    "conv1 = conv2d(_X, wc1, bc1)\n",
    "\n",
    "# Max Pooling (down-sampling)\n",
    "conv1 = max_pool(conv1, k=2)\n",
    "\n",
    "# Aplicando o Dropout\n",
    "conv1 = tf.nn.dropout(conv1, 1 - (keep_prob))\n",
    "\n",
    "# Camada 2 de convolução\n",
    "conv2 = conv2d(conv1,wc2,bc2)\n",
    "\n",
    "# Max Pooling (down-sampling)\n",
    "conv2 = max_pool(conv2, k=2)\n",
    "\n",
    "# Aplicando o Dropout\n",
    "conv2 = tf.nn.dropout(conv2, 1 - (keep_prob))\n",
    "\n",
    "# Camada totalmente conectada\n",
    "dense1 = tf.reshape(conv2, [-1, wd1.get_shape().as_list()[0]]) # Reshape conv2 output to fit dense layer input\n",
    "dense1 = tf.nn.relu(tf.add(tf.matmul(dense1, wd1),bd1)) # Ativação com a Relu \n",
    "dense1 = tf.nn.dropout(dense1, 1 - (keep_prob)) # Aplicando Dropout\n",
    "\n",
    "# Output, class prediction\n",
    "pred = tf.add(tf.matmul(dense1, wout), bout)\n",
    "\n",
    "# Cost Function e Otimização\n",
    "cost = tf.reduce_mean(input_tensor=tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = tf.stop_gradient( y)))\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "# Avaliando o Modelo\n",
    "correct_pred = tf.equal(tf.argmax(input=pred,axis=1), tf.argmax(input=y,axis=1))\n",
    "accuracy = tf.reduce_mean(input_tensor=tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60711d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteração 1280, Perda = 24875.804688, Acurácia em Treino = 0.09375\n",
      "Iteração 2560, Perda = 22211.820312, Acurácia em Treino = 0.17969\n",
      "Iteração 3840, Perda = 11592.819336, Acurácia em Treino = 0.34375\n",
      "Iteração 5120, Perda = 7239.520996, Acurácia em Treino = 0.43750\n",
      "Iteração 6400, Perda = 6545.702148, Acurácia em Treino = 0.44531\n",
      "Iteração 7680, Perda = 4797.838867, Acurácia em Treino = 0.64844\n",
      "Iteração 8960, Perda = 4033.927734, Acurácia em Treino = 0.68750\n",
      "Iteração 10240, Perda = 3594.229492, Acurácia em Treino = 0.65625\n",
      "Iteração 11520, Perda = 4527.885742, Acurácia em Treino = 0.61719\n",
      "Iteração 12800, Perda = 2415.765137, Acurácia em Treino = 0.75781\n",
      "Iteração 14080, Perda = 3205.012695, Acurácia em Treino = 0.71094\n",
      "Iteração 15360, Perda = 1652.137329, Acurácia em Treino = 0.83594\n",
      "Iteração 16640, Perda = 3205.826172, Acurácia em Treino = 0.72656\n",
      "Iteração 17920, Perda = 2594.841309, Acurácia em Treino = 0.80469\n",
      "Iteração 19200, Perda = 2711.838867, Acurácia em Treino = 0.78906\n",
      "Iteração 20480, Perda = 2626.887451, Acurácia em Treino = 0.72656\n",
      "Iteração 21760, Perda = 1754.724243, Acurácia em Treino = 0.80469\n",
      "Iteração 23040, Perda = 1671.870850, Acurácia em Treino = 0.80469\n",
      "Iteração 24320, Perda = 2286.864990, Acurácia em Treino = 0.82812\n",
      "Iteração 25600, Perda = 3145.024414, Acurácia em Treino = 0.74219\n",
      "Iteração 26880, Perda = 2352.045410, Acurácia em Treino = 0.77344\n",
      "Iteração 28160, Perda = 2021.679565, Acurácia em Treino = 0.78125\n",
      "Iteração 29440, Perda = 1808.660156, Acurácia em Treino = 0.85156\n",
      "Iteração 30720, Perda = 1274.943481, Acurácia em Treino = 0.82031\n",
      "Iteração 32000, Perda = 2207.703613, Acurácia em Treino = 0.79688\n",
      "Iteração 33280, Perda = 890.575439, Acurácia em Treino = 0.85156\n",
      "Iteração 34560, Perda = 1510.566650, Acurácia em Treino = 0.82812\n",
      "Iteração 35840, Perda = 1650.708740, Acurácia em Treino = 0.82031\n",
      "Iteração 37120, Perda = 1275.945557, Acurácia em Treino = 0.84375\n",
      "Iteração 38400, Perda = 1252.218018, Acurácia em Treino = 0.85156\n",
      "Iteração 39680, Perda = 1219.101074, Acurácia em Treino = 0.85938\n",
      "Iteração 40960, Perda = 1259.270996, Acurácia em Treino = 0.84375\n",
      "Iteração 42240, Perda = 1013.131104, Acurácia em Treino = 0.86719\n",
      "Iteração 43520, Perda = 1305.839111, Acurácia em Treino = 0.84375\n",
      "Iteração 44800, Perda = 2179.441895, Acurácia em Treino = 0.82031\n",
      "Iteração 46080, Perda = 851.035645, Acurácia em Treino = 0.89844\n",
      "Iteração 47360, Perda = 998.607300, Acurácia em Treino = 0.89844\n",
      "Iteração 48640, Perda = 1067.371338, Acurácia em Treino = 0.82031\n",
      "Iteração 49920, Perda = 887.173706, Acurácia em Treino = 0.85938\n",
      "Iteração 51200, Perda = 787.552246, Acurácia em Treino = 0.90625\n",
      "Iteração 52480, Perda = 1055.721802, Acurácia em Treino = 0.84375\n",
      "Iteração 53760, Perda = 702.725769, Acurácia em Treino = 0.90625\n",
      "Iteração 55040, Perda = 688.200684, Acurácia em Treino = 0.90625\n",
      "Iteração 56320, Perda = 679.847656, Acurácia em Treino = 0.89062\n",
      "Iteração 57600, Perda = 481.343719, Acurácia em Treino = 0.93750\n",
      "Iteração 58880, Perda = 639.280884, Acurácia em Treino = 0.89062\n",
      "Iteração 60160, Perda = 534.311157, Acurácia em Treino = 0.90625\n",
      "Iteração 61440, Perda = 496.472961, Acurácia em Treino = 0.92969\n",
      "Iteração 62720, Perda = 623.175049, Acurácia em Treino = 0.89844\n",
      "Iteração 64000, Perda = 426.631927, Acurácia em Treino = 0.94531\n",
      "Iteração 65280, Perda = 877.982788, Acurácia em Treino = 0.83594\n",
      "Iteração 66560, Perda = 471.828400, Acurácia em Treino = 0.89844\n",
      "Iteração 67840, Perda = 1128.346313, Acurácia em Treino = 0.80469\n",
      "Iteração 69120, Perda = 522.900940, Acurácia em Treino = 0.92188\n",
      "Iteração 70400, Perda = 605.410034, Acurácia em Treino = 0.90625\n",
      "Iteração 71680, Perda = 469.951721, Acurácia em Treino = 0.88281\n",
      "Iteração 72960, Perda = 512.071960, Acurácia em Treino = 0.86719\n",
      "Iteração 74240, Perda = 474.442993, Acurácia em Treino = 0.91406\n",
      "Iteração 75520, Perda = 748.657959, Acurácia em Treino = 0.84375\n",
      "Iteração 76800, Perda = 521.948059, Acurácia em Treino = 0.91406\n",
      "Iteração 78080, Perda = 309.361176, Acurácia em Treino = 0.92969\n",
      "Iteração 79360, Perda = 477.123108, Acurácia em Treino = 0.94531\n",
      "Iteração 80640, Perda = 357.123138, Acurácia em Treino = 0.91406\n",
      "Iteração 81920, Perda = 643.226074, Acurácia em Treino = 0.89062\n",
      "Iteração 83200, Perda = 528.062927, Acurácia em Treino = 0.91406\n",
      "Iteração 84480, Perda = 729.126831, Acurácia em Treino = 0.91406\n",
      "Iteração 85760, Perda = 867.650208, Acurácia em Treino = 0.84375\n",
      "Iteração 87040, Perda = 443.314270, Acurácia em Treino = 0.90625\n",
      "Iteração 88320, Perda = 290.420166, Acurácia em Treino = 0.92969\n",
      "Iteração 89600, Perda = 162.500793, Acurácia em Treino = 0.95312\n",
      "Iteração 90880, Perda = 264.383575, Acurácia em Treino = 0.89844\n",
      "Iteração 92160, Perda = 281.457153, Acurácia em Treino = 0.91406\n",
      "Iteração 93440, Perda = 386.688263, Acurácia em Treino = 0.89062\n",
      "Iteração 94720, Perda = 258.130310, Acurácia em Treino = 0.92188\n",
      "Iteração 96000, Perda = 500.238159, Acurácia em Treino = 0.88281\n",
      "Iteração 97280, Perda = 137.793701, Acurácia em Treino = 0.92188\n",
      "Iteração 98560, Perda = 583.161438, Acurácia em Treino = 0.88281\n",
      "Iteração 99840, Perda = 325.918060, Acurácia em Treino = 0.92969\n",
      "Iteração 101120, Perda = 163.122452, Acurácia em Treino = 0.92188\n",
      "Iteração 102400, Perda = 498.550415, Acurácia em Treino = 0.90625\n",
      "Iteração 103680, Perda = 608.633850, Acurácia em Treino = 0.88281\n",
      "Iteração 104960, Perda = 295.780090, Acurácia em Treino = 0.94531\n",
      "Iteração 106240, Perda = 420.281982, Acurácia em Treino = 0.92188\n",
      "Iteração 107520, Perda = 347.903961, Acurácia em Treino = 0.92969\n",
      "Iteração 108800, Perda = 548.022705, Acurácia em Treino = 0.92969\n",
      "Iteração 110080, Perda = 261.855682, Acurácia em Treino = 0.92969\n",
      "Iteração 111360, Perda = 378.172394, Acurácia em Treino = 0.89062\n",
      "Iteração 112640, Perda = 435.322571, Acurácia em Treino = 0.90625\n",
      "Iteração 113920, Perda = 196.290771, Acurácia em Treino = 0.96094\n",
      "Iteração 115200, Perda = 132.198700, Acurácia em Treino = 0.94531\n",
      "Iteração 116480, Perda = 543.146973, Acurácia em Treino = 0.89844\n",
      "Iteração 117760, Perda = 189.789459, Acurácia em Treino = 0.95312\n",
      "Iteração 119040, Perda = 385.826355, Acurácia em Treino = 0.89062\n",
      "Iteração 120320, Perda = 354.032806, Acurácia em Treino = 0.89062\n",
      "Iteração 121600, Perda = 264.636017, Acurácia em Treino = 0.91406\n",
      "Iteração 122880, Perda = 119.240288, Acurácia em Treino = 0.95312\n",
      "Iteração 124160, Perda = 329.226532, Acurácia em Treino = 0.90625\n",
      "Iteração 125440, Perda = 254.327179, Acurácia em Treino = 0.91406\n",
      "Iteração 126720, Perda = 252.412079, Acurácia em Treino = 0.91406\n",
      "Iteração 128000, Perda = 83.751434, Acurácia em Treino = 0.96094\n",
      "Iteração 129280, Perda = 487.857758, Acurácia em Treino = 0.87500\n",
      "Iteração 130560, Perda = 273.323944, Acurácia em Treino = 0.91406\n",
      "Iteração 131840, Perda = 220.670593, Acurácia em Treino = 0.92188\n",
      "Iteração 133120, Perda = 264.040344, Acurácia em Treino = 0.94531\n",
      "Iteração 134400, Perda = 470.574829, Acurácia em Treino = 0.87500\n",
      "Iteração 135680, Perda = 280.260803, Acurácia em Treino = 0.86719\n",
      "Iteração 136960, Perda = 237.379211, Acurácia em Treino = 0.91406\n",
      "Iteração 138240, Perda = 368.732574, Acurácia em Treino = 0.90625\n",
      "Iteração 139520, Perda = 123.636650, Acurácia em Treino = 0.95312\n",
      "Iteração 140800, Perda = 418.531769, Acurácia em Treino = 0.86719\n",
      "Iteração 142080, Perda = 304.774231, Acurácia em Treino = 0.89844\n",
      "Iteração 143360, Perda = 373.110535, Acurácia em Treino = 0.91406\n",
      "Iteração 144640, Perda = 231.328110, Acurácia em Treino = 0.92969\n",
      "Iteração 145920, Perda = 248.142395, Acurácia em Treino = 0.89844\n",
      "Iteração 147200, Perda = 374.978577, Acurácia em Treino = 0.87500\n",
      "Iteração 148480, Perda = 308.267090, Acurácia em Treino = 0.89844\n",
      "Iteração 149760, Perda = 227.115112, Acurácia em Treino = 0.92188\n",
      "Iteração 151040, Perda = 235.187408, Acurácia em Treino = 0.91406\n",
      "Iteração 152320, Perda = 213.004684, Acurácia em Treino = 0.93750\n",
      "Iteração 153600, Perda = 183.325195, Acurácia em Treino = 0.92188\n",
      "Iteração 154880, Perda = 108.332787, Acurácia em Treino = 0.96094\n",
      "Iteração 156160, Perda = 418.659454, Acurácia em Treino = 0.90625\n",
      "Iteração 157440, Perda = 132.962280, Acurácia em Treino = 0.95312\n",
      "Iteração 158720, Perda = 192.053223, Acurácia em Treino = 0.92969\n",
      "Iteração 160000, Perda = 208.428177, Acurácia em Treino = 0.93750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteração 161280, Perda = 235.860657, Acurácia em Treino = 0.92969\n",
      "Iteração 162560, Perda = 45.115200, Acurácia em Treino = 0.97656\n",
      "Iteração 163840, Perda = 252.933685, Acurácia em Treino = 0.93750\n",
      "Iteração 165120, Perda = 135.918472, Acurácia em Treino = 0.97656\n",
      "Iteração 166400, Perda = 291.245239, Acurácia em Treino = 0.89844\n",
      "Iteração 167680, Perda = 322.442230, Acurácia em Treino = 0.90625\n",
      "Iteração 168960, Perda = 149.889496, Acurácia em Treino = 0.92969\n",
      "Iteração 170240, Perda = 399.613892, Acurácia em Treino = 0.87500\n",
      "Iteração 171520, Perda = 238.798294, Acurácia em Treino = 0.90625\n",
      "Iteração 172800, Perda = 60.749535, Acurácia em Treino = 0.96875\n",
      "Iteração 174080, Perda = 160.367203, Acurácia em Treino = 0.92969\n",
      "Iteração 175360, Perda = 195.264282, Acurácia em Treino = 0.92188\n",
      "Iteração 176640, Perda = 142.182678, Acurácia em Treino = 0.96094\n",
      "Iteração 177920, Perda = 195.435562, Acurácia em Treino = 0.89844\n",
      "Iteração 179200, Perda = 235.758041, Acurácia em Treino = 0.93750\n",
      "Iteração 180480, Perda = 284.325897, Acurácia em Treino = 0.89844\n",
      "Iteração 181760, Perda = 227.688049, Acurácia em Treino = 0.94531\n",
      "Iteração 183040, Perda = 131.559448, Acurácia em Treino = 0.94531\n",
      "Iteração 184320, Perda = 54.649143, Acurácia em Treino = 0.96875\n",
      "Iteração 185600, Perda = 156.632904, Acurácia em Treino = 0.93750\n",
      "Iteração 186880, Perda = 125.189728, Acurácia em Treino = 0.95312\n",
      "Iteração 188160, Perda = 69.555252, Acurácia em Treino = 0.96094\n",
      "Iteração 189440, Perda = 472.307556, Acurácia em Treino = 0.86719\n",
      "Iteração 190720, Perda = 58.845657, Acurácia em Treino = 0.95312\n",
      "Iteração 192000, Perda = 92.164703, Acurácia em Treino = 0.96094\n",
      "Iteração 193280, Perda = 227.007233, Acurácia em Treino = 0.92969\n",
      "Iteração 194560, Perda = 296.791016, Acurácia em Treino = 0.91406\n",
      "Iteração 195840, Perda = 190.728241, Acurácia em Treino = 0.94531\n",
      "Iteração 197120, Perda = 278.006653, Acurácia em Treino = 0.91406\n",
      "Iteração 198400, Perda = 310.451447, Acurácia em Treino = 0.91406\n",
      "Iteração 199680, Perda = 185.939545, Acurácia em Treino = 0.93750\n",
      "Iteração 200960, Perda = 130.048187, Acurácia em Treino = 0.95312\n",
      "Iteração 202240, Perda = 176.964966, Acurácia em Treino = 0.89062\n",
      "Iteração 203520, Perda = 24.269276, Acurácia em Treino = 0.96875\n",
      "Iteração 204800, Perda = 142.474915, Acurácia em Treino = 0.94531\n",
      "Iteração 206080, Perda = 199.342987, Acurácia em Treino = 0.94531\n",
      "Iteração 207360, Perda = 71.258553, Acurácia em Treino = 0.94531\n",
      "Iteração 208640, Perda = 107.869797, Acurácia em Treino = 0.92188\n",
      "Iteração 209920, Perda = 213.098129, Acurácia em Treino = 0.92188\n",
      "Iteração 211200, Perda = 40.048824, Acurácia em Treino = 0.96875\n",
      "Iteração 212480, Perda = 158.672409, Acurácia em Treino = 0.95312\n",
      "Iteração 213760, Perda = 135.328812, Acurácia em Treino = 0.93750\n",
      "Iteração 215040, Perda = 178.035522, Acurácia em Treino = 0.93750\n",
      "Iteração 216320, Perda = 114.190804, Acurácia em Treino = 0.96875\n",
      "Iteração 217600, Perda = 80.770790, Acurácia em Treino = 0.94531\n",
      "Iteração 218880, Perda = 242.682709, Acurácia em Treino = 0.87500\n",
      "Iteração 220160, Perda = 55.887184, Acurácia em Treino = 0.96875\n",
      "Iteração 221440, Perda = 159.291077, Acurácia em Treino = 0.93750\n",
      "Iteração 222720, Perda = 63.779446, Acurácia em Treino = 0.95312\n",
      "Iteração 224000, Perda = 148.875488, Acurácia em Treino = 0.93750\n",
      "Iteração 225280, Perda = 147.464554, Acurácia em Treino = 0.94531\n",
      "Iteração 226560, Perda = 219.322250, Acurácia em Treino = 0.90625\n",
      "Iteração 227840, Perda = 108.946655, Acurácia em Treino = 0.93750\n",
      "Iteração 229120, Perda = 105.638214, Acurácia em Treino = 0.93750\n",
      "Iteração 230400, Perda = 29.756245, Acurácia em Treino = 0.96875\n",
      "Iteração 231680, Perda = 128.666275, Acurácia em Treino = 0.93750\n",
      "Iteração 232960, Perda = 142.210831, Acurácia em Treino = 0.92969\n",
      "Iteração 234240, Perda = 115.403130, Acurácia em Treino = 0.92188\n",
      "Iteração 235520, Perda = 81.772797, Acurácia em Treino = 0.96875\n",
      "Iteração 236800, Perda = 156.299606, Acurácia em Treino = 0.92969\n",
      "Iteração 238080, Perda = 48.265381, Acurácia em Treino = 0.96094\n",
      "Iteração 239360, Perda = 86.012924, Acurácia em Treino = 0.95312\n",
      "Iteração 240640, Perda = 184.403259, Acurácia em Treino = 0.89844\n",
      "Iteração 241920, Perda = 74.847633, Acurácia em Treino = 0.96094\n",
      "Iteração 243200, Perda = 62.130440, Acurácia em Treino = 0.92969\n",
      "Iteração 244480, Perda = 72.556976, Acurácia em Treino = 0.96094\n",
      "Iteração 245760, Perda = 105.638321, Acurácia em Treino = 0.95312\n",
      "Iteração 247040, Perda = 74.998810, Acurácia em Treino = 0.92188\n",
      "Iteração 248320, Perda = 104.803162, Acurácia em Treino = 0.90625\n",
      "Iteração 249600, Perda = 252.286957, Acurácia em Treino = 0.89844\n",
      "Otimização Concluída!\n",
      "Acurácia em Teste: 0.953125\n"
     ]
    }
   ],
   "source": [
    "# Inicializando as variáveis\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "# Sessão\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Mantém o treinamento até atingir o número máximo de iterações\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # Fit training usando batch data\n",
    "        sess.run(optimizer, feed_dict = {x: batch_xs, y: batch_ys, keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculando a acurácia\n",
    "            acc = sess.run(accuracy, feed_dict = {x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
    "            # Calculando a perda\n",
    "            loss = sess.run(cost, feed_dict = {x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
    "            print (\"Iteração \" + str(step*batch_size) + \", Perda = \" + \"{:.6f}\".format(loss) + \", Acurácia em Treino = \" + \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print (\"Otimização Concluída!\")\n",
    "    \n",
    "    # Calculando acurácia para 256 mnist test images\n",
    "    print (\"Acurácia em Teste:\", sess.run(accuracy, feed_dict = {x: mnist.test.images[:256], y: mnist.test.labels[:256], keep_prob: 1.}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
