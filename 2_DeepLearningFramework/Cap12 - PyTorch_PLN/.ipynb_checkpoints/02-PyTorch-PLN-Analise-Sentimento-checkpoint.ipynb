{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.7\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo um Classificador de Sentimentos com PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tudo o que expressamos (verbalmente ou por escrito) carrega enormes quantidades de informação. O tópico que escolhemos, nosso tom, nossa seleção de palavras, tudo acrescenta algum tipo de informação que pode ser interpretada e com o valor extraído dela. Em teoria, podemos entender e até prever o comportamento humano usando essas informações.\n",
    "\n",
    "Mas há um problema: uma pessoa pode gerar centenas ou milhares de palavras em uma declaração, cada sentença com sua complexidade correspondente. Se você deseja dimensionar e analisar várias centenas, milhares ou milhões de pessoas ou declarações em uma determinada região, a situação é incontrolável.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm.notebook import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Rodrigo Abreu\n",
      "\n",
      "pandas : 1.3.4\n",
      "sklearn: 0.24.2\n",
      "torch  : 1.10.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Rodrigo Abreu\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define o device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando e Explorando os Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos um dataset disponível publicamente em https://www.imdb.com/interfaces/.\n",
    "\n",
    "Os labels de sentimentos foram extraídos do portal: https://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "nomes_colunas = ['Review', 'Sentimento']\n",
    "dados_filmes = pd.read_csv('dados/imdb_reviews.csv', sep = '\\t', names = nomes_colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza\n",
    "dados_filmes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "dados_filmes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a proporção de sentimentos\n",
    "dados_filmes['Sentimento'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representação Bag-of-Words\n",
    "\n",
    "![](imagens/bag2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imagens/bag1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imagens/bag3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imagens/bag4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulação de Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começamos criando um \"vetorizador\".\n",
    "\n",
    "Convertemos uma coleção de documentos de texto em uma matriz de contagens de tokens.\n",
    "\n",
    "Essa implementação produz uma representação esparsa das contagens usando scipy.sparse.csr_matrix.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos um vectorizer\n",
    "vectorizer = CountVectorizer(stop_words = 'english', max_df = 0.99, min_df = 0.005)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraímos as sequências do texto aplicando o vetorizador\n",
    "sequences = vectorizer.fit_transform(dados_filmes.Review.tolist())\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza como dataframe\n",
    "print(pd.DataFrame(sequences).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organiza os labels (sentimentos)\n",
    "labels = dados_filmes.Sentimento.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza uma amostra\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos o saco de palavras (vocabulário)\n",
    "token2idx = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipo\n",
    "type(token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total\n",
    "print(len(token2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza\n",
    "token2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantas vezes a palavra \"movie\" aparece nas avaliações?\n",
    "token2idx['movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E a palavra good?\n",
    "token2idx['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para facilitar nosso trabalho, vamos inverter chaves e colunas em nosso dicionário\n",
    "idx2token = {idx: token for token, idx in token2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipo\n",
    "type(idx2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total\n",
    "print(len(idx2token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza\n",
    "idx2token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos resumir tudo que fizemos em uma função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos uma classe para extrair as frases\n",
    "class Sequences():\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(stop_words = 'english', max_df = 0.99, min_df = 0.005)\n",
    "        self.sequences = self.vectorizer.fit_transform(dados_filmes.Review.tolist())\n",
    "        self.labels = dados_filmes.Sentimento.tolist()\n",
    "        self.token2idx = self.vectorizer.vocabulary_\n",
    "        self.idx2token = {idx: token for token, idx in self.token2idx.items()}\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.sequences[i, :].toarray(), self.labels[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sequences.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai as frases do dataset e cria a matriz de dados, como os tokens, contagens e labels\n",
    "dados_frases = Sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confere o shape\n",
    "print(dados_frases[5][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara os dados para treinamento no formato PyTorch\n",
    "train_loader = DataLoader(dados_frases, batch_size = 4096)\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição e Construção do Modelo\n",
    "\n",
    "Camada 1: $$x_1 = W_1 X + b_1$$\n",
    "Função de Ativação: $$h_1 = \\textrm{Relu}(x_1)$$\n",
    "Camada 2: $$x_2 = W_2 h_1 + b_2$$\n",
    "Saída: $$p = \\sigma(x_2)$$\n",
    "Loss: $$L = −(ylog(p)+(1−y)log(1−p))$$\n",
    "Gradiente: \n",
    "$$\\frac{\\partial }{\\partial W_1}L(W_1, b_1, W_2, b_2) = \\frac{\\partial L}{\\partial p}\\frac{\\partial p}{\\partial x_2}\\frac{\\partial x_2}{\\partial h_1}\\frac{\\partial h_1}{\\partial x_1}\\frac{\\partial x_1}{\\partial W_1}$$\n",
    "\n",
    "Atualização de Parâmetros:\n",
    "$$W_1 = W_1 - \\alpha \\frac{\\partial L}{\\partial W_1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificador\n",
    "class BagOfWordsClassifier(nn.Module):\n",
    "    \n",
    "    # Método construtor para inicializar os atributos\n",
    "    def __init__(self, vocab_size, hidden1, hidden2):\n",
    "        super(BagOfWordsClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(vocab_size, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, 1)\n",
    "    \n",
    "    # Método para a passada para a frente (forward)\n",
    "    def forward(self, inputs):\n",
    "        x = F.relu(self.fc1(inputs.squeeze(1).float()))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o modelo\n",
    "modelo = BagOfWordsClassifier(len(dados_frases.token2idx), 128, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza\n",
    "modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a função de perda (loss) usaremos Binary Cross Entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a função de perda\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o otimizador usaremos o algoritmo ADAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam dinamicamente altera a taxa de aprendizagem\n",
    "optimizer = optim.Adam([p for p in modelo.parameters() if p.requires_grad], lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora treinamos o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "\n",
    "# Instância de treinamento do modelo\n",
    "modelo.train()\n",
    "\n",
    "# Lista para armazenar os erros a cada passada de treinamento\n",
    "train_losses = []\n",
    "\n",
    "# Número de épocas\n",
    "epochs = 12\n",
    "\n",
    "# Loop de treinamento\n",
    "for epoch in range(epochs): \n",
    "    \n",
    "    # Barra de progresso\n",
    "    progress_bar = tqdm_notebook(train_loader, leave = False)\n",
    "    \n",
    "    # Listas de controle\n",
    "    losses = []\n",
    "    total = 0\n",
    "    \n",
    "    # Loop\n",
    "    for inputs, target in progress_bar:\n",
    "        \n",
    "        # Modelo\n",
    "        modelo.zero_grad()\n",
    "\n",
    "        # Saída (previsão do modelo)\n",
    "        output = modelo(inputs)\n",
    "        \n",
    "        # Cálculo do erro\n",
    "        loss = criterion(output.squeeze(), target.float())\n",
    "        \n",
    "        # Instância do Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Prepara atualização dos parâmetros (coeficientes)    \n",
    "        nn.utils.clip_grad_norm_(modelo.parameters(), 3)\n",
    "\n",
    "        # Executa o otimizador\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Atualiza a barra de progresso\n",
    "        progress_bar.set_description(f'\\nErro do Modelo: {loss.item():.3f}')\n",
    "        \n",
    "        # Erros e total\n",
    "        losses.append(loss.item())\n",
    "        total += 1\n",
    "    \n",
    "    # Erro da epoch\n",
    "    epoch_loss = sum(losses) / total\n",
    "    \n",
    "    # Erro de treinamento\n",
    "    train_losses.append(epoch_loss)\n",
    "        \n",
    "    tqdm.write(f'Epoch #{epoch + 1}\\tErro em Treinamento: {epoch_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsões de Sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para prever o sentimento\n",
    "def predict_sentiment(text):\n",
    "    \n",
    "    # Carrega o modelo\n",
    "    modelo.eval()\n",
    "    \n",
    "    # Extrai as previsões do modelo\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Texto recebido como parâmetro convertido para vetor\n",
    "        test_vector = torch.LongTensor(dados_frases.vectorizer.transform([text]).toarray())\n",
    "\n",
    "        # Previsão\n",
    "        output = modelo(test_vector)\n",
    "        \n",
    "        # Gera a previsão final como probabilidade\n",
    "        prediction = torch.sigmoid(output).item()\n",
    "\n",
    "        # Checa a probabilidade com limite de 0.5\n",
    "        if prediction >= 0.5:\n",
    "            print(f'{prediction:0.3}: Sentimento Positivo')\n",
    "        else:\n",
    "            print(f'{prediction:0.3}: Sentimento Negativo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro calculamos o valor sigmóide (entre 0 e 1) para a previsão.\n",
    "\n",
    "Se for maior ou igual que 0,5 classificamos como sentimento Positivo e se for menor que 0.5 classificamos como sentimento Negativo. \n",
    "\n",
    "Vamos testar o classificador de sentimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto de avaliação de filme\n",
    "test_text = \"\"\"\n",
    "This poor excuse for a movie is terrible. It has been 'so good it's bad' for a\n",
    "while, and the high ratings are a good form of sarcasm, I have to admit. But\n",
    "now it has to stop. Technically inept, spoon-feeding mundane messages with the\n",
    "artistic weight of an eighties' commercial, hypocritical to say the least, it\n",
    "deserves to fall into oblivion. Mr. Derek, I hope you realize you are like that\n",
    "weird friend that everybody know is lame, but out of kindness and Christian\n",
    "duty is treated like he's cool or something. That works if you are a good\n",
    "decent human being, not if you are a horrible arrogant bully like you are. Yes,\n",
    "Mr. 'Daddy' Derek will end on the history books of the internet for being a\n",
    "delusional sour old man who thinks to be a good example for kids, but actually\n",
    "has a poster of Kim Jong-Un in his closet. Destroy this movie if you all have a\n",
    "conscience, as I hope IHE and all other youtube channel force-closed by Derek\n",
    "out of SPITE would destroy him in the courts.This poor excuse for a movie is\n",
    "terrible. It has been 'so good it's bad' for a while, and the high ratings are\n",
    "a good form of sarcasm, I have to admit. But now it has to stop. Technically\n",
    "inept, spoon-feeding mundane messages with the artistic weight of an eighties'\n",
    "commercial, hypocritical to say the least, it deserves to fall into oblivion.\n",
    "Mr. Derek, I hope you realize you are like that weird friend that everybody\n",
    "know is lame, but out of kindness and Christian duty is treated like he's cool\n",
    "or something. That works if you are a good decent human being, not if you are a\n",
    "horrible arrogant bully like you are. Yes, Mr. 'Daddy' Derek will end on the\n",
    "history books of the internet for being a delusional sour old man who thinks to\n",
    "be a good example for kids, but actually has a poster of Kim Jong-Un in his\n",
    "closet. Destroy this movie if you all have a conscience, as I hope IHE and all\n",
    "other youtube channel force-closed by Derek out of SPITE would destroy him in\n",
    "the courts.\n",
    "\"\"\"\n",
    "\n",
    "# Previsão\n",
    "predict_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto de avaliação de filme\n",
    "test_text = \"\"\"\n",
    "Cool Cat Saves The Kids is a symbolic masterpiece directed by Derek Savage that\n",
    "is not only satirical in the way it makes fun of the media and politics, but in\n",
    "the way in questions as how we humans live life and how society tells us to\n",
    "live life.\n",
    "\n",
    "Before I get into those details, I wanna talk about the special effects in this\n",
    "film. They are ASTONISHING, and it shocks me that Cool Cat Saves The Kids got\n",
    "snubbed by the Oscars for Best Special Effects. This film makes 2001 look like\n",
    "garbage, and the directing in this film makes Stanley Kubrick look like the\n",
    "worst director ever. You know what other film did that? Birdemic: Shock and\n",
    "Terror. Both of these films are masterpieces, but if I had to choose my\n",
    "favorite out of the 2, I would have to go with Cool Cat Saves The Kids. It is\n",
    "now my 10th favorite film of all time.\n",
    "\n",
    "Now, lets get into the symbolism: So you might be asking yourself, Why is Cool\n",
    "Cat Orange? Well, I can easily explain. Orange is a color. Orange is also a\n",
    "fruit, and its a very good fruit. You know what else is good? Good behavior.\n",
    "What behavior does Cool Cat have? He has good behavior. This cannot be a\n",
    "coincidence, since cool cat has good behavior in the film.\n",
    "\n",
    "Now, why is Butch The Bully fat? Well, fat means your wide. You wanna know who\n",
    "was wide? Hitler. Nuff said this cannot be a coincidence.\n",
    "\n",
    "Why does Erik Estrada suspect Butch The Bully to be a bully? Well look at it\n",
    "this way. What color of a shirt was Butchy wearing when he walks into the area?\n",
    "I don't know, its looks like dark purple/dark blue. Why rhymes with dark? Mark.\n",
    "Mark is that guy from the Room. The Room is the best movie of all time. What is\n",
    "the opposite of best? Worst. This is how Erik knew Butch was a bully.\n",
    "\n",
    "and finally, how come Vivica A. Fox isn't having a successful career after\n",
    "making Kill Bill.\n",
    "\n",
    "I actually can't answer that question.\n",
    "\n",
    "Well thanks for reading my review.\n",
    "\"\"\"\n",
    "\n",
    "# Previsão\n",
    "predict_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto de avaliação de filme\n",
    "test_text = \"\"\"\n",
    "What the heck is this ? There is not one redeeming quality about this terrible\n",
    "and very poorly done \"movie\". I can't even say that it's a \"so bad it's good\n",
    "movie\".It is undeniably pointless to address all the things wrong here but\n",
    "unfortunately even the \"life lessons\" about bullies and stuff like this are so\n",
    "wrong and terrible that no kid should hear them.The costume is also horrible\n",
    "and the acting...just unbelievable.No effort whatsoever was put into this thing\n",
    "and it clearly shows,I have no idea what were they thinking or who was it even\n",
    "meant for. I feel violated after watching this trash and I deeply recommend you\n",
    "stay as far away as possible.This is certainly one of the worst pieces of c***\n",
    "I have ever seen.\n",
    "\"\"\"\n",
    "\n",
    "# Previsão\n",
    "predict_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto de avaliação de filme\n",
    "test_text = \"\"\"\n",
    "Don't let any bullies out there try and shape your judgment on this gem of a\n",
    "title.\n",
    "\n",
    "Some people really don't have anything better to do, except trash a great movie\n",
    "with annoying 1-star votes and spread lies on the Internet about how \"dumb\"\n",
    "Cool Cat is.\n",
    "\n",
    "I wouldn't be surprised to learn if much of the unwarranted negativity hurled\n",
    "at this movie is coming from people who haven't even watched this movie for\n",
    "themselves in the first place. Those people are no worse than the Butch the\n",
    "Bully, the film's repulsive antagonist.\n",
    "\n",
    "As it just so happens, one of the main points of \"Cool Cat Saves the Kids\" is\n",
    "in addressing the attitudes of mean naysayers who try to demean others who\n",
    "strive to bring good attitudes and fun vibes into people's lives. The message\n",
    "to be learned here is that if one is friendly and good to others, the world is\n",
    "friendly and good to one in return, and that is cool. Conversely, if one is\n",
    "miserable and leaving 1-star votes on IMDb, one is alone and doesn't have any\n",
    "friends at all. Ain't that the truth?\n",
    "\n",
    "The world has uncovered a great, new, young filmmaking talent in \"Cool Cat\"\n",
    "creator Derek Savage, and I sure hope that this is only the first of many\n",
    "amazing films and stories that the world has yet to appreciate.\n",
    "\n",
    "If you are a cool person who likes to have lots of fun, I guarantee that this\n",
    "is a movie with charm that will uplift your spirits and reaffirm your positive\n",
    "attitudes towards life.\n",
    "\"\"\"\n",
    "\n",
    "# Previsão\n",
    "predict_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
