{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ativando ambiente virtual com python 3.7\n",
    "!conda activate detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 24 22:56:18 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 462.30       Driver Version: 462.30       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1650   WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   44C    P8     2W /  N/A |    489MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3856    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      5180    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     10036    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     11324    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     13504    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     14476    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     17068    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     17364    C+G   Insufficient Permissions        N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o OpenCV\n",
    "#!pip install -q opencv-python==4.2.0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o OpenCV Headless\n",
    "# !pip install -q opencv-python-headless==4.2.0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "wauAzIX65I6_",
    "outputId": "a483e868-c7fc-416b-86b0-1b84612c24a4"
   },
   "outputs": [],
   "source": [
    "# Instala API COCO (formato dos dados para treinar os modelos)\n",
    "#!pip install -q 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala PyTorch com suporte a plataforma CUDA (somente para computadores com GPU)\n",
    "#!pip install -q -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala pacote para suporte a C++\n",
    "#!pip install -q cython "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala pyyaml\n",
    "#!pip install -q --ignore-installed pyyaml==5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9S6wIc2Oti_c"
   },
   "source": [
    "As duas células abaixo devem ser executadas somente na primeira vez que executar este Jupyter na máquina. \n",
    "\n",
    "**Isso deve ser feito somente na primeira execução deste notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "rmev2LhSCWFw",
    "outputId": "172ae1e2-9a2a-4400-eaf9-07f6e9475840"
   },
   "outputs": [],
   "source": [
    "# Clone do repositório do Detectron2\n",
    "# Seu computador pode não ter o Git instalado. Acesse este link e instale de acordo com seu sistema operacional:\n",
    "# https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\n",
    "#!git clone https://github.com/facebookresearch/detectron2 detectron2_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o Detectron2\n",
    "# Somente na primeira vez que executar este Jupyter Notebook\n",
    "#!pip install -q -e detectron2_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVGrjW_Gt4Gq"
   },
   "source": [
    ">Uma vez instaladas as dependências acima, você precisará reiniciar o Jupyter Notebook no terminal. Salve este notebook, feche-o, pare o Jupyter Notebook, inicie novamente e continue o trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RMHd00OAt11C",
    "outputId": "7cdce634-4c69-4baf-840f-8b23cd543f79"
   },
   "outputs": [],
   "source": [
    "# Imports gerais\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import ntpath\n",
    "import random\n",
    "import urllib\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import PIL.Image as Image\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Detectron2\n",
    "import detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# Gráficos e Imagens\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Formatação das imagens\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "# Seed\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "xijZDV9nektU",
    "outputId": "ef16814f-b638-42a0-e887-8ad63b573318"
   },
   "outputs": [],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4XN0qCWz4nL"
   },
   "source": [
    "## Conjunto de Dados\n",
    "\n",
    "Nosso conjunto de dados é fornecido por [Dataturks](https://dataturks.com/), e está disponível no [Kaggle](https://www.kaggle.com/dataturks/face-detection-in-images). \n",
    "\n",
    "O dataset:\n",
    "\n",
    "> Temos cerca de 500 imagens com 1100 faces marcadas manualmente através da caixa delimitadora.\n",
    "\n",
    "Fiz o download do arquivo JSON que contém as anotações. Vamos carregá-lo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "L7Bq4GNDzLc1",
    "outputId": "02101c56-fde1-4b94-9795-9b26bf5499f7"
   },
   "outputs": [],
   "source": [
    "# Carrega o arquivo JSON\n",
    "faces_df = pd.read_json('dicionarios/face_detection.json', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza o conteúdo\n",
    "faces_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKQeltR927BM"
   },
   "source": [
    "Cada linha contém uma anotação de face única. Observe que várias linhas podem apontar para uma única imagem (por exemplo, várias faces por imagem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97eCU2d9SQBB"
   },
   "source": [
    "## Pré-Processamento de Dados\n",
    "\n",
    "O conjunto de dados contém apenas URLs e anotações de imagem. Teremos que baixar as imagens. Também normalizamos as anotações, para que seja mais fácil usá-las com o Detectron2 posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o diretório para gravar as imagens\n",
    "os.makedirs(\"faces\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para receber os dados\n",
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QEX1UwGV33h4",
    "outputId": "70d01226-25c4-44e9-89ac-d634d43fe07c"
   },
   "outputs": [],
   "source": [
    "# Loop\n",
    "for index, row in tqdm(faces_df.iterrows(), total = faces_df.shape[0]):\n",
    "    \n",
    "    # Define a url de cada imagem\n",
    "    img = urllib.request.urlopen(row[\"content\"])\n",
    "    \n",
    "    # Abre a imagem\n",
    "    img = Image.open(img)\n",
    "    \n",
    "    # Converte para RGB (3 cores)\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    # Define o nome da imagem\n",
    "    image_name = f'face_{index}.jpeg'\n",
    "\n",
    "    # Salva a imagem emdisco\n",
    "    img.save(f'faces/{image_name}', \"JPEG\")\n",
    "    \n",
    "    # Obtém a anotação (label da imagem)\n",
    "    annotations = row['annotation']\n",
    "    \n",
    "    # Loop pela anotação de cada imagem\n",
    "    for an in annotations:\n",
    "\n",
    "        # Dicionário\n",
    "        data = {}\n",
    "\n",
    "        # Largura, altura e pontos da imagem\n",
    "        width = an['imageWidth']\n",
    "        height = an['imageHeight']\n",
    "        points = an['points']\n",
    "\n",
    "        # Nome, largura e altura da imagem\n",
    "        data['file_name'] = image_name\n",
    "        data['width'] = width\n",
    "        data['height'] = height\n",
    "\n",
    "        # Coordenadas da bounding box (caixa delimitadora) de cada face na imagem\n",
    "        data[\"x_min\"] = int(round(points[0][\"x\"] * width))\n",
    "        data[\"y_min\"] = int(round(points[0][\"y\"] * height))\n",
    "        data[\"x_max\"] = int(round(points[1][\"x\"] * width))\n",
    "        data[\"y_max\"] = int(round(points[1][\"y\"] * height))\n",
    "\n",
    "        # Nome da classe\n",
    "        data['class_name'] = 'face'\n",
    "\n",
    "        # Grava o resultado na lista\n",
    "        dataset.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQoBe8RxhUQU"
   },
   "source": [
    "Vamos colocar os dados em um dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ih4HkzfNUpsd",
    "outputId": "3e8f6ac9-d4a0-476f-d9a8-1f043712c7c8"
   },
   "outputs": [],
   "source": [
    "# Converte a lista em um dataframe\n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X_XoG7oSUrT7",
    "outputId": "855fe5c9-d523-440a-8b47-db13655c98aa"
   },
   "outputs": [],
   "source": [
    "# Shape\n",
    "print(df.file_name.unique().shape[0], df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lXaR93rbi8Pz"
   },
   "source": [
    "Temos um total de 409 imagens e 1132 anotações. Vamos salvá-los no disco (para que você possa reutilizá-los)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b__0PPh60tZ-"
   },
   "outputs": [],
   "source": [
    "# Gravando as anotações\n",
    "df.to_csv('dicionarios/annotations.csv', header = True, index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kTnG9MkHjnKd"
   },
   "source": [
    "### Análise Exploratória\n",
    "\n",
    "Vamos ver alguns exemplos de dados anotados. Usaremos o OpenCV para carregar uma imagem, adicionar as caixas delimitadoras e redimensioná-la. Definiremos uma função auxiliar para fazer tudo isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zwCL9lsSAda"
   },
   "outputs": [],
   "source": [
    "# Função visualizar as imagens a partir das anotações\n",
    "def annotate_image(annotations, resize = True):\n",
    "    \n",
    "    # Nome do arquivo\n",
    "    file_name = annotations.file_name.to_numpy()[0]\n",
    "    \n",
    "    # Leitura da imagem com OpenCV\n",
    "    img = cv2.cvtColor(cv2.imread(f'faces/{file_name}'), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Busca as anotações \n",
    "    for i, a in annotations.iterrows():    \n",
    "        cv2.rectangle(img, (a.x_min, a.y_min), (a.x_max, a.y_max), (0, 255, 0), 2)\n",
    "\n",
    "    # Redimensiona a imagem se necessário\n",
    "    if not resize:\n",
    "        return img\n",
    "\n",
    "    # Retroa a imagem\n",
    "    return cv2.resize(img, (384, 384), interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "80cUVP83k2o3",
    "outputId": "3f9c6bdb-e412-40e9-df20-7b6f1b61055b"
   },
   "outputs": [],
   "source": [
    "# Visualizando uma imagem com anotação\n",
    "img_df = df[df.file_name == df.file_name.unique()[5]]\n",
    "img = annotate_image(img_df, resize = False)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "colab_type": "code",
    "id": "bhJNfLcclKTW",
    "outputId": "cf630a8d-b924-4b35-a16a-4d04e425c988"
   },
   "outputs": [],
   "source": [
    "# Visualizando uma imagem com anotação\n",
    "img_df = df[df.file_name == df.file_name.unique()[9]]\n",
    "img = annotate_image(img_df, resize = False)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "303IKbrQOSjw"
   },
   "source": [
    "Essas são boas, as anotações são claramente visíveis. Podemos usar o torchvision para criar uma grade de imagens. Observe que as imagens estão em vários tamanhos, então vamos redimensioná-las."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jfATJdCiXXBH"
   },
   "outputs": [],
   "source": [
    "# Obtendo amostras de imagens\n",
    "sample_images = [annotate_image(df[df.file_name == f]) for f in df.file_name.unique()[:10]]\n",
    "sample_images = torch.as_tensor(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4wNqZxG-KCKy",
    "outputId": "ae6fa427-181f-4ce6-de46-681728763cf7"
   },
   "outputs": [],
   "source": [
    "# Shape do tensor\n",
    "sample_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqCi0xt5G5pS"
   },
   "outputs": [],
   "source": [
    "# Precisamos ajustar o shape\n",
    "sample_images = sample_images.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9qFznK8sKFSB",
    "outputId": "b13cfb66-7cc9-4b37-c9ac-66304aeaa1a5"
   },
   "outputs": [],
   "source": [
    "# Shape\n",
    "sample_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "colab_type": "code",
    "id": "Gc2UEpTbASzD",
    "outputId": "739dd605-7e2f-4fa5-e020-8dd5f94fe118"
   },
   "outputs": [],
   "source": [
    "# Plot de várias imagens em grid\n",
    "plt.figure(figsize = (24, 12))\n",
    "grid_img = torchvision.utils.make_grid(sample_images, nrow = 5)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxRyNq-5O19z"
   },
   "source": [
    "Você pode ver claramente que algumas anotações estão ausentes (coluna 4). Teremos que lidar com isso de alguma forma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5aG0Gb1xR2zv"
   },
   "source": [
    "## Preparando os Dados Para o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "r0tuPADAw69d",
    "outputId": "28eebb78-f13e-4d68-9f3f-6241fa2b384e"
   },
   "outputs": [],
   "source": [
    "# Carregamos as anotações\n",
    "df = pd.read_csv('dicionarios/annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório das imagens\n",
    "IMAGES_PATH = f'faces'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna imagens únicas\n",
    "unique_files = df.file_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara os dados de treino e de teste\n",
    "# O train_test_split clássico não funcionaria aqui, porque queremos uma divisão entre os nomes dos arquivos.\n",
    "train_files = set(np.random.choice(unique_files, int(len(unique_files) * 0.95), replace = False))\n",
    "train_df = df[df.file_name.isin(train_files)]\n",
    "test_df = df[~df.file_name.isin(train_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de treino\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQDdB3yHxvm7"
   },
   "outputs": [],
   "source": [
    "# Obtém as classes\n",
    "classes = df.class_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temos como classe de saída apenas a face na imagem\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHkbICHfS_LI"
   },
   "source": [
    "Em seguida, escreveremos uma função que converte nosso conjunto de dados em um formato usado pelo Detectron2, o COCO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eh6stJEoeTbG"
   },
   "outputs": [],
   "source": [
    "# Função para colocar as imagens em formato COCO\n",
    "def create_dataset_dicts(df, classes):\n",
    "    \n",
    "    # Lista para os dicionários de classe\n",
    "    dataset_dicts = []\n",
    "        \n",
    "    # Loop por cada imagem\n",
    "    for image_id, img_name in enumerate(df.file_name.unique()):\n",
    "\n",
    "        # Dicionário\n",
    "        record = {}\n",
    "\n",
    "        # Imagem\n",
    "        image_df = df[df.file_name == img_name]\n",
    "\n",
    "        # Caminho\n",
    "        file_path = f'{IMAGES_PATH}/{img_name}'\n",
    "        \n",
    "        # Dados da imagem\n",
    "        record[\"file_name\"] = file_path\n",
    "        record[\"image_id\"] = image_id\n",
    "        record[\"height\"] = int(image_df.iloc[0].height)\n",
    "        record[\"width\"] = int(image_df.iloc[0].width)\n",
    "\n",
    "        # Objetos\n",
    "        objs = []\n",
    "    \n",
    "        # Loop\n",
    "        for _, row in image_df.iterrows():\n",
    "\n",
    "            # Coordenadas\n",
    "            xmin = int(row.x_min)\n",
    "            ymin = int(row.y_min)\n",
    "            xmax = int(row.x_max)\n",
    "            ymax = int(row.y_max)\n",
    "\n",
    "            poly = [(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)]\n",
    "            poly = list(itertools.chain.from_iterable(poly))\n",
    "\n",
    "            obj = {\"bbox\": [xmin, ymin, xmax, ymax], \n",
    "                   \"bbox_mode\": BoxMode.XYXY_ABS, \n",
    "                   \"segmentation\": [poly], \n",
    "                   \"category_id\": classes.index(row.class_name), \n",
    "                   \"iscrowd\": 0}\n",
    "    \n",
    "            objs.append(obj)\n",
    "\n",
    "    record[\"annotations\"] = objs\n",
    "    dataset_dicts.append(record)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "saOEmpLqW1tK"
   },
   "source": [
    "Convertemos cada linha de anotação em um único registro com uma lista de anotações. Você também pode perceber que estamos criando um polígono exatamente da mesma forma que a caixa delimitadora. Isso é necessário para os modelos de segmentação de imagens no Detectron2.\n",
    "\n",
    "Você precisará registrar seu conjunto de dados nos catálogos de conjunto de dados e metadados. Faremos isso na célula abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjhVau86xMCa"
   },
   "outputs": [],
   "source": [
    "# Registrando o conjunto de dados\n",
    "for d in [\"train\", \"val\"]:\n",
    "    DatasetCatalog.register(\"faces_\" + d, lambda d=d: create_dataset_dicts(train_df if d == \"train\" else test_df, classes))\n",
    "    MetadataCatalog.get(\"faces_\" + d).set(thing_classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando os metadados\n",
    "statement_metadata = MetadataCatalog.get(\"faces_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JDZvlcyZdMf"
   },
   "source": [
    "Infelizmente, o avaliador para o conjunto de testes não é incluído por padrão. Podemos resolver isso facilmente, escrevendo nossa própria classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UsgI41N9xHa"
   },
   "outputs": [],
   "source": [
    "# Classe paar trenar e avaliar o modelo\n",
    "class treinaModelo(DefaultTrainer):\n",
    "  \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder = None):\n",
    "\n",
    "        if output_folder is None:\n",
    "            os.makedirs(\"eval\", exist_ok = True)\n",
    "            output_folder = \"eval\"\n",
    "\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vYyKENuZZm5v"
   },
   "source": [
    "Os resultados da avaliação serão armazenados na pasta `eval` se nenhuma pasta for fornecida.\n",
    "\n",
    "O ajuste fino de um modelo Detectron2 não é nada como escrever código PyTorch. Carregaremos um arquivo de configuração, alteraremos alguns valores e iniciaremos o processo de treinamento. \n",
    "\n",
    "Usaremos o modelo pré-treinado Mask R-CNN X101-FPN. \n",
    "\n",
    "Esse modelo foi pré-treinado no dataset [COCO dataset](http://cocodataset.org/#home) e alcança um desempenho muito bom. A desvantagem é que é lento para treinar.\n",
    "\n",
    "Vamos carregar o arquivo de configuração e os pesos do modelo pré-treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rIib8zgaf1sl"
   },
   "outputs": [],
   "source": [
    "# Inicia o arquivo de configuração\n",
    "cfg = get_cfg()\n",
    "\n",
    "# Carrega o arquivo de configuração\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "\n",
    "# Carrega os pesos do modelo pré-treinado\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmIU6TvKgWfe"
   },
   "outputs": [],
   "source": [
    "# Especificamos os conjuntos de dados (nós os registramos) que usaremos para treinamento e avaliação\n",
    "cfg.DATASETS.TRAIN = (\"faces_train\",)\n",
    "cfg.DATASETS.TEST = (\"faces_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OnQDunrbgYMX"
   },
   "outputs": [],
   "source": [
    "# E para o otimizador, definiremos alguns valores. Fique à vontade para alterar esses valores e re-treinar o modelo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.MAX_ITER = 1500\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "cfg.SOLVER.STEPS = (1000, 1500)\n",
    "cfg.SOLVER.GAMMA = 0.05\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)\n",
    "cfg.TEST.EVAL_PERIOD = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5xcfeR_jOyj"
   },
   "source": [
    "Os primeiros 3 parâmetros são padrões (tamanho do lote, número máximo de iterações e taxa de aprendizado).\n",
    "\n",
    "Mas temos ainda:\n",
    "\n",
    "- `WARMUP_ITERS` - a taxa de aprendizado começa em 0 e vai para a predefinida para este número de iterações\n",
    "- `STEPS` - os pontos de verificação (número de iterações) nos quais a taxa de aprendizado será reduzida em `GAMMA`\n",
    "\n",
    "Por fim, especificaremos o número de classes e o período em que avaliaremos no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checamos se o diretório de saída existe\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HX-nqwfak0in"
   },
   "source": [
    "E então treinamos o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Fm-1luynzTiD",
    "outputId": "d7f16dcb-8ff6-4f01-cb74-8d4863d51ce8"
   },
   "outputs": [],
   "source": [
    "# Carregamos as configurações\n",
    "trainer = treinaModelo(cfg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos iniciar o treinamento do zero e não de onde parou\n",
    "trainer.resume_or_load(resume = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Treinamento - Dura 30 minutos no Titan\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório e nome do modelo\n",
    "cfg.MODEL.WEIGHTS = os.path.join(\"output\", \"model_final.pth\")\n",
    "\n",
    "# Define o threshold de teste para o modelo\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.75\n",
    "\n",
    "# Salva o preditor\n",
    "preditor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SRaCjOJADyeD"
   },
   "source": [
    "## Avaliando o Modelo\n",
    "\n",
    "A avaliação de modelos de detecção de objetos é um pouco diferente quando comparada à avaliação de modelos padrão de classificação ou regressão.\n",
    "\n",
    "A principal métrica que você precisa conhecer é IoU (interseção sobre união). Ele mede a sobreposição entre dois limites - o predito e a verdade fundamental. Pode obter valores entre 0 e 1.\n",
    "\n",
    "$$\\text{IoU}=\\frac{\\text{area of overlap}}{\\text{area of union}}$$\n",
    "\n",
    "Usando IoU, pode-se definir um limite (por exemplo > 0,5) para classificar se uma previsão é um verdadeiro positivo (TP) ou um falso positivo (FP).\n",
    "\n",
    "Agora você pode calcular a precisão média (AP) tomando a área sob a curva de precisão e recuperação. Isso deve fornecer uma compreensão prática de como os modelos de detecção de objetos são avaliados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OzLLfo90eI_t",
    "outputId": "01c09de8-712a-469f-80ba-6cf8a6294466"
   },
   "outputs": [],
   "source": [
    "# Resultado da avaliação\n",
    "evaluator = COCOEvaluator(\"faces_val\", cfg, False, output_dir = \"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"faces_val\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T3BUEjZ-nuvX"
   },
   "source": [
    "### Detecção Facial\n",
    "\n",
    "Vamos ver o modelo funciona e fazer detecção facial em novas imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CsXDCLuxH34u"
   },
   "outputs": [],
   "source": [
    "# Define o diretório\n",
    "os.makedirs(\"annotated_results\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém as imagens\n",
    "test_image_paths = test_df.file_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H0O32pFpHbBh"
   },
   "outputs": [],
   "source": [
    "# Aqui fazemos detecção para cada imagem de teste\n",
    "for teste_image in test_image_paths:\n",
    "    file_path = f'{IMAGES_PATH}/{teste_image}'\n",
    "    im = cv2.imread(file_path)\n",
    "    outputs = preditor(im)\n",
    "    v = Visualizer(im[:, :, ::-1], metadata = statement_metadata, scale = 1., instance_mode = ColorMode.IMAGE)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    instances.remove('pred_masks')\n",
    "    v = v.draw_instance_predictions(instances)\n",
    "    result = v.get_image()[:, :, ::-1]\n",
    "    file_name = ntpath.basename(teste_image)\n",
    "    write_res = cv2.imwrite(f'annotated_results/{file_name}', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yzEfY1P7n0r-"
   },
   "source": [
    "Vamos conferir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UY7qtFf4ez3e"
   },
   "outputs": [],
   "source": [
    "annotated_images = [f'annotated_results/{f}' for f in test_df.file_name.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "id": "TUMAe0CbeAbm",
    "outputId": "b7c5d8fe-180c-4e9a-e005-de9ecc7cde38"
   },
   "outputs": [],
   "source": [
    "# Detectando faces em imagens\n",
    "img = cv2.cvtColor(cv2.imread(annotated_images[5]), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "id": "a324bTYae1nA",
    "outputId": "097cdba6-79be-4856-ad8c-c5588a681f36"
   },
   "outputs": [],
   "source": [
    "# Detectando faces em imagens\n",
    "img = cv2.cvtColor(cv2.imread(annotated_images[3]), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "id": "RguwQjKcfC6K",
    "outputId": "3210669d-c1e6-42c1-f24a-52a8ed9d6f6d"
   },
   "outputs": [],
   "source": [
    "# Detectando faces em imagens\n",
    "img = cv2.cvtColor(cv2.imread(annotated_images[11]), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "wSCw_Uehf89k",
    "outputId": "477f8a60-5be6-49b3-de06-50ee7b23e049"
   },
   "outputs": [],
   "source": [
    "# Detectando faces em imagens\n",
    "img = cv2.cvtColor(cv2.imread(annotated_images[9]), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wigVQpmAoMvw"
   },
   "source": [
    "O modelo funcionou bem! Perceba que alguns erros ocorrram, o que é normal. Experimente ajustar os hiperparâmetros e treinar o modelo por mais tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VazlZcDu2VK-"
   },
   "source": [
    "## Conclusão\n",
    "\n",
    "Parabéns! Agora você sabe como usar o Detectron2 com PyTorch para detecção de objetos! Usar modelos pré-treinados pode ser uma arma poderosa para construir aplicações de Visão Computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "02.face-detection-with-detectron2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
