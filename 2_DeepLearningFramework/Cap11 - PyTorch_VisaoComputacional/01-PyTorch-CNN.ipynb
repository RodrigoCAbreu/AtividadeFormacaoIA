{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Deep Learning Frameworks</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.7.6\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neurais Convolucionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Rede Neural Convolucional (CNN) é uma tecnologia de rede neural que impactou profundamente a área de Visão Computacional. Fukushima (1980) introduziu o conceito original de uma rede neural convolutiva, e LeCun, Bottou, Bengio & Haffner (1998) melhoraram muito este trabalho. A partir desta pesquisa, Yan LeCun apresentou a famosa arquitetura de rede neural LeNet-5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem similaridades e diferenças entre as CNNs e outros modelos de DNNs:\n",
    "\n",
    "Normalmente usamos a classificação, embora a regressão ainda seja uma opção.\n",
    "A entrada para a rede neural agora é 3D (altura, largura, cor)\n",
    "Os dados não são transformados; sem zscores ou variáveis dummy.\n",
    "O tempo de processamento é muito maior.\n",
    "Agora temos diferentes camadas: camadas densas (como antes), camadas de convolução e camadas de Max Pooling.\n",
    "Os dados não chegarão mais como arquivos CSV. O TensorFlow fornece alguns utilitários para ir diretamente da imagem para o input de uma rede neural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora a Visão Computacional use principalmente CNNs, essa tecnologia possui aplicações em outras áreas. É possível utilizar CNNs em dados não visuais, mas nesse caso você deve encontrar uma maneira de codificar seus dados para que possa imitar as propriedades dos dados visuais. As CNNs são semelhantes à arquitetura de Mapas Auto Organizáveis (SOM - Self Organizing Maps). A ordem dos elementos vetoriais é crucial para o treinamento. Em contraste, a maioria das redes neurais que não são CNNs ou SOMs tratam seus dados de entrada como um vetor de valores, e a ordem em que você organiza as características de entrada neste vetor é irrelevante. Para esses tipos de redes neurais, você não pode alterar a ordem depois de ter treinado a rede. Em outras palavras, CNNs e SOMs não seguem o tratamento padrão de vetores de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente, uma rede neural feedforward comum cria todas as possíveis conexões de peso entre duas camadas. Na terminologia de aprendizagem profunda, nos referimos a essas camadas como camadas densas. Além de não representar todo o peso possível, as redes neurais convolutivas também compartilharão pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Para Visão Computacional\n",
    "\n",
    "## CIFAR Data Set\n",
    "\n",
    "Os datasets [CIFAR-10 and CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html) também são frequentemente usados pela comunidade de pesquisa de rede neural.\n",
    "\n",
    "![CIFAR](imagens/cifar.png \"CIFAR\")\n",
    "\n",
    "O conjunto de dados CIFAR-10 contém imagens divididas em 10 classes. O conjunto de dados CIFAR-100 contém 100 classes em uma hierarquia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Learning e Classificação\n",
    "\n",
    "![CNN](imagens/cnn.jpg \"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para sumarizar o modelo\n",
    "!pip install -q torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchvision 0.5.0\n",
      "numpy       1.18.2\n",
      "torch       1.4.0\n",
      "Data Science Academy\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura do Modelo\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.html#conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNN](imagens/convolution.gif \"Convolução\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNN](imagens/stride.png \"Stride\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNN](imagens/padding.png \"Padding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de Camada de Convolução\n",
    "nn.Conv2d(3, 16, 3, stride = 2, padding = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe Para o Modelo\n",
    "class ModeloCNN(nn.Module):\n",
    "    \n",
    "    # Construtor da Classe\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Camada de Entrada\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding = 1)\n",
    "        \n",
    "        # Primeira Camada Oculta\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n",
    "        \n",
    "        # Segunda Camada Oculta\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        \n",
    "        # Camada de Pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Transformação Linear 1 (Camada Densa)\n",
    "        self.linear1 = nn.Linear(64 * 4 * 4, 512)\n",
    "        \n",
    "        # Transformação Linear 2 (Camada Densa)\n",
    "        self.linear2 = nn.Linear(512, 10) \n",
    "        \n",
    "        # Camada de Dropout Para Regularização\n",
    "        self.dropout = nn.Dropout(p = 0.3)\n",
    "    \n",
    "    # Método de Avanço da Rede\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando as Transformações Para os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformações Para os Dados de Entrada\n",
    "transformations = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando e Dividindo os Dados em Treino, Teste e Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Carrega os Dados de Treino\n",
    "train_data = datasets.CIFAR10('CIFAR10', train = True, download = True, transform = transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Carrega os Dados de Teste\n",
    "test_data = datasets.CIFAR10('CIFAR10', train = False, download = True, transform = transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tamanho dos Datasets\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho Para Dados de Validação\n",
    "validation_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho Para Dados de Treino\n",
    "training_size = len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Índice \n",
    "indices = list(range(training_size))\n",
    "np.random.shuffle(indices)\n",
    "index_split = int(np.floor(training_size * validation_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Índices Para Dados de Treino e Validação\n",
    "validation_indices, training_indices = indices[:index_split], indices[index_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amostras de Treino e Validação\n",
    "training_sample = SubsetRandomSampler(training_indices)\n",
    "validation_sample = SubsetRandomSampler(validation_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros\n",
    "batch_size = 16\n",
    "n_epochs = 30\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera as Amostras Finais de Dados\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, sampler = training_sample)\n",
    "valid_loader = DataLoader(train_data, batch_size = batch_size, sampler = validation_sample)\n",
    "test_loader = DataLoader(train_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o Modelo (Instância da Classe)\n",
    "model = ModeloCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeloCNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (linear2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifica o Dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Envia o Modelo para a GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Função de Custo Baseada em Cross Entropia\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o Otimizador (Backward)\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função Para Acurácia\n",
    "def accuracy(preds, y):\n",
    "    _, pred = torch.argmax(preds, 1)\n",
    "    correct = pred.eq(target.data.view_as(pred))\n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Erro em Treino: 2.089 | Erro em Validação: 1.765 |\n",
      "| Epoch: 02 | Erro em Treino: 1.672 | Erro em Validação: 1.540 |\n",
      "| Epoch: 03 | Erro em Treino: 1.512 | Erro em Validação: 1.394 |\n",
      "| Epoch: 04 | Erro em Treino: 1.415 | Erro em Validação: 1.313 |\n",
      "| Epoch: 05 | Erro em Treino: 1.347 | Erro em Validação: 1.256 |\n",
      "| Epoch: 06 | Erro em Treino: 1.283 | Erro em Validação: 1.175 |\n",
      "| Epoch: 07 | Erro em Treino: 1.226 | Erro em Validação: 1.144 |\n",
      "| Epoch: 08 | Erro em Treino: 1.182 | Erro em Validação: 1.114 |\n",
      "| Epoch: 09 | Erro em Treino: 1.143 | Erro em Validação: 1.049 |\n",
      "| Epoch: 10 | Erro em Treino: 1.110 | Erro em Validação: 1.033 |\n",
      "| Epoch: 11 | Erro em Treino: 1.082 | Erro em Validação: 1.008 |\n",
      "| Epoch: 12 | Erro em Treino: 1.054 | Erro em Validação: 0.988 |\n",
      "| Epoch: 13 | Erro em Treino: 1.027 | Erro em Validação: 0.955 |\n",
      "| Epoch: 14 | Erro em Treino: 1.004 | Erro em Validação: 0.936 |\n",
      "| Epoch: 15 | Erro em Treino: 0.981 | Erro em Validação: 0.918 |\n",
      "| Epoch: 16 | Erro em Treino: 0.962 | Erro em Validação: 0.879 |\n",
      "| Epoch: 17 | Erro em Treino: 0.946 | Erro em Validação: 0.856 |\n",
      "| Epoch: 18 | Erro em Treino: 0.930 | Erro em Validação: 0.861 |\n",
      "| Epoch: 19 | Erro em Treino: 0.909 | Erro em Validação: 0.850 |\n",
      "| Epoch: 20 | Erro em Treino: 0.891 | Erro em Validação: 0.829 |\n",
      "| Epoch: 21 | Erro em Treino: 0.871 | Erro em Validação: 0.819 |\n",
      "| Epoch: 22 | Erro em Treino: 0.863 | Erro em Validação: 0.813 |\n",
      "| Epoch: 23 | Erro em Treino: 0.854 | Erro em Validação: 0.807 |\n",
      "| Epoch: 24 | Erro em Treino: 0.841 | Erro em Validação: 0.787 |\n",
      "| Epoch: 25 | Erro em Treino: 0.832 | Erro em Validação: 0.795 |\n",
      "| Epoch: 26 | Erro em Treino: 0.819 | Erro em Validação: 0.786 |\n",
      "| Epoch: 27 | Erro em Treino: 0.811 | Erro em Validação: 0.774 |\n",
      "| Epoch: 28 | Erro em Treino: 0.800 | Erro em Validação: 0.784 |\n",
      "| Epoch: 29 | Erro em Treino: 0.780 | Erro em Validação: 0.754 |\n",
      "| Epoch: 30 | Erro em Treino: 0.778 | Erro em Validação: 0.767 |\n"
     ]
    }
   ],
   "source": [
    "# Looop\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    # Inicializa o Erro a Cada Epoch\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    # Cria Objeto de Treinamento do Modelo\n",
    "    model.train()\n",
    "    \n",
    "    # Para Cada Batch de Dados Executa o Treinamento\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # Cria Objeto de Avaliação do Modelo    \n",
    "    model.eval()\n",
    "    \n",
    "    # Para Cada Batch de Dados Executa a Avaliiação\n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # Calcula o Erro na Epoch\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "    \n",
    "    # Print\n",
    "    print(f'| Epoch: {epoch:02} | Erro em Treino: {train_loss:.3f} | Erro em Validação: {valid_loss:.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo treinado\n",
    "torch.save(model.state_dict(), \"modelos/cifar10.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
